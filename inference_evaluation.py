# inference_evaluation.py
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error, r2_score
import os
import pickle
import time
from train_pinn_transformer_multitask import PrinterPINN_MultiTask, Config

class NozzleInferenceEvaluator:
    def __init__(self, model_path, config_path=None):
        """
        åˆå§‹åŒ–æ¨ç†è¯„ä¼°å™¨
        :param model_path: è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„
        :param config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœæœ‰ï¼‰
        """
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"ğŸš€ åˆå§‹åŒ–æ¨ç†è¯„ä¼°å™¨ | è®¾å¤‡: {self.device}")
        
        # åŠ è½½æ¨¡å‹
        self.model, self.config = self.load_model(model_path, config_path)
        
        # åŠ è½½å½’ä¸€åŒ–å‚æ•°
        self.load_normalization_params()
        
        print("âœ… æ¨ç†è¯„ä¼°å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def load_model(self, model_path, config_path=None):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å’Œé…ç½®"""
        print(f"ğŸ“¥ åŠ è½½æ¨¡å‹: {model_path}")
        
        # å¦‚æœæœ‰å•ç‹¬çš„é…ç½®æ–‡ä»¶ï¼ŒåŠ è½½å®ƒ
        if config_path and os.path.exists(config_path):
            with open(config_path, 'rb') as f:
                config = pickle.load(f)
        else:
            # ä½¿ç”¨é»˜è®¤é…ç½®
            config = Config()
        
        # åˆ›å»ºæ¨¡å‹
        model = PrinterPINN_MultiTask(config)
        
        # åŠ è½½æ¨¡å‹æƒé‡
        checkpoint = torch.load(model_path, map_location='cpu')
        model.load_state_dict(checkpoint['model_state_dict'])
        
        model = model.to(self.device)
        model.eval()
        
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ | è¾“å…¥ç»´åº¦: {config.input_dim}, è¾“å‡ºç»´åº¦: {config.output_dim}")
        return model, config
    
    def load_normalization_params(self):
        """åŠ è½½å½’ä¸€åŒ–å‚æ•°"""
        params_path = os.path.join(self.config.checkpoint_dir, 'normalization_params.pkl')
        
        if os.path.exists(params_path):
            with open(params_path, 'rb') as f:
                params = pickle.load(f)
            
            self.mean_X = params['mean_X']
            self.std_X = params['std_X']
            self.ctrl_cols = params['ctrl_cols']
            self.state_cols = params['state_cols']
            
            print("ğŸ“Š å½’ä¸€åŒ–å‚æ•°åŠ è½½æˆåŠŸ")
            print(f"   å¹³å‡å€¼: {self.mean_X}")
            print(f"   æ ‡å‡†å·®: {self.std_X}")
        else:
            raise FileNotFoundError(f"å½’ä¸€åŒ–å‚æ•°æ–‡ä»¶ä¸å­˜åœ¨: {params_path}")
    
    def preprocess_data(self, data_df, seq_len, pred_len):
        """
        é¢„å¤„ç†æ•°æ®ç”¨äºæ¨ç†
        :param data_df: pandas DataFrameï¼ŒåŒ…å«ä¼ æ„Ÿå™¨æ•°æ®
        :param seq_len: å†å²çª—å£é•¿åº¦
        :param pred_len: é¢„æµ‹é•¿åº¦
        :return: å¤„ç†åçš„å¼ é‡
        """
        print("âš™ï¸  é¢„å¤„ç†æ•°æ®...")
        
        # ç¡®ä¿æ•°æ®æŒ‰æ—¶é—´æˆ³æ’åº
        if 'timestamp' in data_df.columns:
            data_df = data_df.sort_values('timestamp')
        
        # é€‰æ‹©éœ€è¦çš„åˆ—
        all_cols = self.ctrl_cols + self.state_cols
        if 'hour' in data_df.columns:
            all_cols.append('hour')
        
        # æå–æ•°æ®
        data_array = data_df[all_cols].values.astype(np.float32)
        
        # å½’ä¸€åŒ–
        normalized_data = (data_array - self.mean_X) / self.std_X
        
        # æå–æ§åˆ¶ä¿¡å·
        ctrl_data = data_df[self.ctrl_cols].values.astype(np.float32)
        normalized_ctrl = (ctrl_data - self.mean_X[:len(self.ctrl_cols)]) / self.std_X[:len(self.ctrl_cols)]
        
        # åˆ›å»ºæ»‘åŠ¨çª—å£
        n_samples = len(data_array) - seq_len - pred_len + 1
        if n_samples <= 0:
            raise ValueError(f"æ•°æ®å¤ªçŸ­ï¼Œæ— æ³•åˆ›å»ºçª—å£ã€‚éœ€è¦è‡³å°‘ {seq_len + pred_len} ä¸ªæ ·æœ¬ï¼Œä½†åªæœ‰ {len(data_array)} ä¸ªæ ·æœ¬ã€‚")
        
        X_hist = np.zeros((n_samples, seq_len, self.config.input_dim), dtype=np.float32)
        X_ctrl = np.zeros((n_samples, pred_len, len(self.ctrl_cols)), dtype=np.float32)
        
        for i in range(n_samples):
            X_hist[i] = normalized_data[i:i+seq_len]
            X_ctrl[i] = normalized_ctrl[i+seq_len:i+seq_len+pred_len]
        
        print(f"âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ | æ ·æœ¬æ•°: {n_samples}")
        print(f"   X_hist shape: {X_hist.shape}")
        print(f"   X_ctrl shape: {X_ctrl.shape}")
        
        return torch.tensor(X_hist).to(self.device), torch.tensor(X_ctrl).to(self.device), data_df
    
    def predict(self, data_df, batch_size=32):
        """
        è¿›è¡Œé¢„æµ‹
        :param data_df: è¾“å…¥æ•°æ® DataFrame
        :param batch_size: æ‰¹æ¬¡å¤§å°
        :return: é¢„æµ‹ç»“æœå­—å…¸
        """
        print("ğŸ§  è¿›è¡Œæ¨ç†é¢„æµ‹...")
        
        # é¢„å¤„ç†æ•°æ®
        X_hist, X_ctrl, original_df = self.preprocess_data(data_df, self.config.seq_len, self.config.pred_len)
        
        n_samples = X_hist.shape[0]
        physics_preds = []
        class_preds = []
        rul_preds = []
        
        start_time = time.time()
        
        with torch.no_grad():
            for i in range(0, n_samples, batch_size):
                batch_end = min(i + batch_size, n_samples)
                batch_hist = X_hist[i:batch_end]
                batch_ctrl = X_ctrl[i:batch_end]
                
                outputs = self.model(batch_hist, batch_ctrl)
                
                # ç‰©ç†åœºé‡æ„
                physics_pred = outputs['physics_pred'].cpu().numpy()
                physics_preds.append(physics_pred)
                
                # æ•…éšœåˆ†ç±»
                class_pred = torch.softmax(outputs['class_pred'], dim=1).cpu().numpy()
                class_preds.append(class_pred)
                
                # RULé¢„æµ‹
                rul_pred = outputs['rul_pred'].cpu().numpy()
                rul_preds.append(rul_pred)
        
        # åˆå¹¶ç»“æœ
        physics_preds = np.concatenate(physics_preds, axis=0)
        class_preds = np.concatenate(class_preds, axis=0)
        rul_preds = np.concatenate(rul_preds, axis=0)
        
        inference_time = time.time() - start_time
        print(f"âœ… æ¨ç†å®Œæˆ | æ ·æœ¬æ•°: {n_samples} | è€—æ—¶: {inference_time:.2f}s | ååé‡: {n_samples/inference_time:.1f} æ ·æœ¬/ç§’")
        
        return {
            'physics_preds': physics_preds,
            'class_preds': class_preds,
            'rul_preds': rul_preds,
            'timestamps': original_df['timestamp'].values[self.config.seq_len:self.config.seq_len + n_samples],
            'machine_ids': original_df['machine_id'].values[self.config.seq_len:self.config.seq_len + n_samples]
        }
    
    def evaluate(self, predictions, ground_truth_df):
        """
        è¯„ä¼°é¢„æµ‹ç»“æœ
        :param predictions: predict()æ–¹æ³•çš„è¾“å‡º
        :param ground_truth_df: åŒ…å«çœŸå®æ ‡ç­¾çš„DataFrame
        """
        print("\n" + "="*60)
        print("ğŸ“Š è¯„ä¼°é¢„æµ‹ç»“æœ")
        print("="*60)
        
        # 1. ç‰©ç†åœºé‡æ„è¯„ä¼°
        self.evaluate_physics_reconstruction(predictions, ground_truth_df)
        
        # 2. æ•…éšœåˆ†ç±»è¯„ä¼°
        self.evaluate_fault_classification(predictions, ground_truth_df)
        
        # 3. RULé¢„æµ‹è¯„ä¼°
        self.evaluate_rul_prediction(predictions, ground_truth_df)
        
        # 4. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self.generate_comprehensive_report(predictions, ground_truth_df)
    
    def evaluate_physics_reconstruction(self, predictions, ground_truth_df):
        """è¯„ä¼°ç‰©ç†åœºé‡æ„æ€§èƒ½"""
        print("\nğŸ”§ 1. ç‰©ç†åœºé‡æ„è¯„ä¼°")
        
        # æå–çœŸå®å€¼
        start_idx = self.config.seq_len
        end_idx = start_idx + len(predictions['physics_preds'])
        ground_truth = ground_truth_df[self.state_cols].values[start_idx:end_idx]
        
        # åå½’ä¸€åŒ–é¢„æµ‹å€¼
        physics_preds = predictions['physics_preds']
        # åªå¯¹çŠ¶æ€åˆ—è¿›è¡Œåå½’ä¸€åŒ–
        state_start_idx = len(self.ctrl_cols)
        state_end_idx = state_start_idx + len(self.state_cols)
        state_mean = self.mean_X[state_start_idx:state_end_idx]
        state_std = self.std_X[state_start_idx:state_end_idx]
        
        # åå½’ä¸€åŒ–
        physics_preds_denorm = physics_preds * state_std + state_mean
        
        # è¯„ä¼°æ¯ä¸ªç‰©ç†é‡
        metrics = {}
        for i, col in enumerate(self.state_cols):
            true_vals = ground_truth[:, i]
            pred_vals = physics_preds_denorm[:, -1, i]  # ä½¿ç”¨æœ€åä¸€æ­¥çš„é¢„æµ‹
            
            mse = mean_squared_error(true_vals, pred_vals)
            rmse = np.sqrt(mse)
            mae = np.mean(np.abs(true_vals - pred_vals))
            r2 = r2_score(true_vals, pred_vals)
            
            metrics[col] = {
                'MSE': mse,
                'RMSE': rmse,
                'MAE': mae,
                'R2': r2
            }
            
            print(f"   {col:20s} | MSE: {mse:.6f} | RMSE: {rmse:.6f} | MAE: {mae:.6f} | R2: {r2:.4f}")
        
        # å¯è§†åŒ–ä¸»è¦ç‰©ç†é‡
        self.plot_physics_reconstruction(physics_preds_denorm, ground_truth, metrics)
        
        return metrics
    
    def evaluate_fault_classification(self, predictions, ground_truth_df):
        """è¯„ä¼°æ•…éšœåˆ†ç±»æ€§èƒ½"""
        print("\nğŸš¨ 2. æ•…éšœåˆ†ç±»è¯„ä¼°")
        
        # æå–çœŸå®æ ‡ç­¾
        start_idx = self.config.seq_len
        end_idx = start_idx + len(predictions['class_preds'])
        true_fault_labels = ground_truth_df['fault_label'].values[start_idx:end_idx]
        true_fault_types = ground_truth_df['fault_type'].values[start_idx:end_idx]
        
        # è½¬æ¢é¢„æµ‹ç»“æœ
        pred_probs = predictions['class_preds']
        pred_classes = np.argmax(pred_probs, axis=1)
        
        # å°†çœŸå®æ•…éšœç±»å‹è½¬æ¢ä¸ºåˆ†ç±»æ ‡ç­¾
        true_classes = np.zeros_like(true_fault_labels, dtype=int)
        fault_mask = (true_fault_labels == 1)
        true_classes[fault_mask] = true_fault_types[fault_mask].astype(int)
        true_classes = np.clip(true_classes, 0, self.config.class_dim-1)
        
        # è®¡ç®—æŒ‡æ ‡
        accuracy = np.mean(pred_classes == true_classes)
        
        print(f"   å‡†ç¡®ç‡: {accuracy:.4f}")
        print("\n" + classification_report(true_classes, pred_classes, 
                                          target_names=['Normal', 'Nozzle Clog', 'Mechanical Loose', 'Motor Fault']))
        
        # æ··æ·†çŸ©é˜µ
        cm = confusion_matrix(true_classes, pred_classes)
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['Normal', 'Nozzle Clog', 'Mechanical Loose', 'Motor Fault'],
                    yticklabels=['Normal', 'Nozzle Clog', 'Mechanical Loose', 'Motor Fault'])
        plt.title('æ•…éšœåˆ†ç±»æ··æ·†çŸ©é˜µ')
        plt.xlabel('é¢„æµ‹ç±»åˆ«')
        plt.ylabel('çœŸå®ç±»åˆ«')
        plt.savefig(os.path.join(self.config.checkpoint_dir, 'inference_confusion_matrix.png'))
        plt.close()
        
        print(f"   æ··æ·†çŸ©é˜µå·²ä¿å­˜: {os.path.join(self.config.checkpoint_dir, 'inference_confusion_matrix.png')}")
        
        return accuracy, cm
    
    def evaluate_rul_prediction(self, predictions, ground_truth_df):
        """è¯„ä¼°RULé¢„æµ‹æ€§èƒ½"""
        print("\nâ³ 3. RULé¢„æµ‹è¯„ä¼°")
        
        # æå–çœŸå®RUL
        start_idx = self.config.seq_len
        end_idx = start_idx + len(predictions['rul_preds'])
        
        # è®¡ç®—çœŸå®RULï¼ˆç®€åŒ–ç‰ˆï¼‰
        true_rul = np.zeros(end_idx - start_idx)
        machine_ids = ground_truth_df['machine_id'].values[start_idx:end_idx]
        
        unique_machines = np.unique(machine_ids)
        for mid in unique_machines:
            mask = (machine_ids == mid)
            fault_labels = ground_truth_df['fault_label'].values[start_idx:end_idx][mask]
            
            if np.any(fault_labels == 1):
                fault_indices = np.where(fault_labels == 1)[0]
                first_fault_idx = fault_indices[0]
                
                # è®¡ç®—æ¯ä¸ªæ—¶é—´ç‚¹åˆ°æ•…éšœçš„æ—¶é—´
                for i in range(len(mask)):
                    if i < first_fault_idx:
                        steps_to_fault = first_fault_idx - i
                        true_rul[mask][i] = steps_to_fault * 0.001  # è½¬æ¢ä¸ºç§’
                    else:
                        true_rul[mask][i] = 0
            else:
                # æ— æ•…éšœæœºå™¨ï¼Œè®¾ç½®ä¸ºæœ€å¤§RUL
                true_rul[mask] = 3600  # 1å°æ—¶
        
        # åå½’ä¸€åŒ–é¢„æµ‹çš„RUL
        pred_rul = predictions['rul_preds'].flatten() * 3600  # ä»[0,1]æ˜ å°„å›[0,3600]ç§’
        
        # è¯„ä¼°
        mse = mean_squared_error(true_rul, pred_rul)
        rmse = np.sqrt(mse)
        mae = np.mean(np.abs(true_rul - pred_rul))
        r2 = r2_score(true_rul, pred_rul)
        
        print(f"   RULé¢„æµ‹æ€§èƒ½:")
        print(f"      MSE: {mse:.2f} ç§’Â²")
        print(f"      RMSE: {rmse:.2f} ç§’")
        print(f"      MAE: {mae:.2f} ç§’")
        print(f"      R2: {r2:.4f}")
        
        # å¯è§†åŒ–
        plt.figure(figsize=(12, 6))
        plt.plot(true_rul[:1000], 'b-', label='çœŸå®RUL', alpha=0.7)
        plt.plot(pred_rul[:1000], 'r--', label='é¢„æµ‹RUL', alpha=0.7)
        plt.xlabel('æ ·æœ¬ç´¢å¼•')
        plt.ylabel('RUL (ç§’)')
        plt.title('RULé¢„æµ‹å¯¹æ¯”')
        plt.legend()
        plt.grid(True)
        plt.savefig(os.path.join(self.config.checkpoint_dir, 'rul_prediction_comparison.png'))
        plt.close()
        
        print(f"   RULå¯¹æ¯”å›¾å·²ä¿å­˜: {os.path.join(self.config.checkpoint_dir, 'rul_prediction_comparison.png')}")
        
        return {
            'MSE': mse,
            'RMSE': rmse,
            'MAE': mae,
            'R2': r2
        }
    
    def plot_physics_reconstruction(self, physics_preds, ground_truth, metrics):
        """ç»˜åˆ¶ç‰©ç†åœºé‡æ„ç»“æœ"""
        fig, axes = plt.subplots(3, 2, figsize=(15, 12))
        fig.suptitle('ç‰©ç†åœºé‡æ„ç»“æœå¯¹æ¯”', fontsize=16)
        
        plot_cols = ['temperature_C', 'vibration_disp_x_m', 'vibration_disp_y_m', 
                    'motor_current_x_A', 'pressure_bar', 'print_quality']
        
        for i, col in enumerate(plot_cols):
            if col not in self.state_cols:
                continue
            
            col_idx = self.state_cols.index(col)
            ax = axes[i//2, i%2]
            
            # å–å‰1000ä¸ªæ ·æœ¬è¿›è¡Œå¯è§†åŒ–
            n_plot = min(1000, len(ground_truth))
            true_vals = ground_truth[:n_plot, col_idx]
            pred_vals = physics_preds[:n_plot, -1, col_idx]  # ä½¿ç”¨æœ€åä¸€æ­¥çš„é¢„æµ‹
            
            ax.plot(true_vals, 'b-', label='çœŸå®å€¼', alpha=0.7)
            ax.plot(pred_vals, 'r--', label='é¢„æµ‹å€¼', alpha=0.7)
            ax.set_title(f'{col}\nRMSE: {metrics[col]["RMSE"]:.6f}')
            ax.legend()
            ax.grid(True)
        
        plt.tight_layout()
        plot_path = os.path.join(self.config.checkpoint_dir, 'physics_reconstruction.png')
        plt.savefig(plot_path)
        plt.close()
        
        print(f"   ç‰©ç†åœºé‡æ„å›¾å·²ä¿å­˜: {plot_path}")
    
    def generate_comprehensive_report(self, predictions, ground_truth_df):
        """ç”Ÿæˆç»¼åˆè¯„ä¼°æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“‹ ç”Ÿæˆç»¼åˆè¯„ä¼°æŠ¥å‘Š")
        print("="*60)
        
        report_path = os.path.join(self.config.checkpoint_dir, 'inference_evaluation_report.txt')
        
        with open(report_path, 'w') as f:
            f.write("3Dæ‰“å°æœºPINN-Transformeræ¨¡å‹æ¨ç†è¯„ä¼°æŠ¥å‘Š\n")
            f.write("="*60 + "\n")
            f.write(f"è¯„ä¼°æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æ¨¡å‹è·¯å¾„: {os.path.abspath(self.config.checkpoint_dir)}/best_multitask_model.pth\n")
            f.write(f"æ•°æ®æ ·æœ¬æ•°: {len(predictions['timestamps'])}\n\n")
            
            # å…³é”®æŒ‡æ ‡æ‘˜è¦
            f.write("å…³é”®æ€§èƒ½æŒ‡æ ‡æ‘˜è¦:\n")
            f.write("-"*40 + "\n")
            
            # ç‰©ç†åœºé‡æ„æ‘˜è¦
            f.write("1. ç‰©ç†åœºé‡æ„æ€§èƒ½:\n")
            for col in ['temperature_C', 'vibration_disp_x_m', 'vibration_disp_y_m']:
                if col in self.state_cols:
                    col_idx = self.state_cols.index(col)
                    ground_truth = ground_truth_df[col].values[self.config.seq_len:self.config.seq_len + len(predictions['physics_preds'])]
                    pred_vals = predictions['physics_preds'][:, -1, col_idx] * self.std_X[len(self.ctrl_cols)+col_idx] + self.mean_X[len(self.ctrl_cols)+col_idx]
                    
                    rmse = np.sqrt(mean_squared_error(ground_truth, pred_vals))
                    f.write(f"   {col:20s}: RMSE = {rmse:.6f}\n")
            
            # æ•…éšœåˆ†ç±»æ‘˜è¦
            f.write("\n2. æ•…éšœåˆ†ç±»æ€§èƒ½:\n")
            pred_classes = np.argmax(predictions['class_preds'], axis=1)
            true_classes = np.zeros_like(pred_classes)
            true_fault_labels = ground_truth_df['fault_label'].values[self.config.seq_len:self.config.seq_len + len(pred_classes)]
            true_fault_types = ground_truth_df['fault_type'].values[self.config.seq_len:self.config.seq_len + len(pred_classes)]
            
            fault_mask = (true_fault_labels == 1)
            true_classes[fault_mask] = true_fault_types[fault_mask].astype(int)
            true_classes = np.clip(true_classes, 0, self.config.class_dim-1)
            
            accuracy = np.mean(pred_classes == true_classes)
            f.write(f"   å‡†ç¡®ç‡: {accuracy:.4f}\n")
            
            # RULé¢„æµ‹æ‘˜è¦
            f.write("\n3. RULé¢„æµ‹æ€§èƒ½:\n")
            true_rul = np.zeros(len(predictions['rul_preds']))
            pred_rul = predictions['rul_preds'].flatten() * 3600
            
            # ç®€åŒ–çš„RULè®¡ç®—
            for i in range(len(true_rul)):
                if true_fault_labels[i] == 0:  # æ— æ•…éšœ
                    true_rul[i] = 3600
                else:
                    true_rul[i] = 0
            
            rmse_rul = np.sqrt(mean_squared_error(true_rul, pred_rul))
            f.write(f"   RMSE: {rmse_rul:.2f} ç§’\n")
            
            f.write("\n" + "="*60 + "\n")
            f.write("è¯¦ç»†ç»“æœè¯·æŸ¥çœ‹ç”Ÿæˆçš„å›¾åƒæ–‡ä»¶:\n")
            f.write(f"   - physics_reconstruction.png\n")
            f.write(f"   - inference_confusion_matrix.png\n")
            f.write(f"   - rul_prediction_comparison.png\n")
        
        print(f"âœ… ç»¼åˆè¯„ä¼°æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")

# ==================== ä¸»å‡½æ•° ====================
def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤ºæ¨ç†è¯„ä¼°æµç¨‹"""
    # é…ç½®å‚æ•°
    model_path = './checkpoints_multitask/best_multitask_model.pth'
    data_path = 'printer_dataset/nozzle_simulation_gear_print.csv'
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    if not os.path.exists(data_path):
        raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
    
    print("ğŸš€ 3Dæ‰“å°æœºPINN-Transformeræ¨ç†è¯„ä¼°ç³»ç»Ÿ")
    print("="*70)
    
    # åŠ è½½è¯„ä¼°å™¨
    evaluator = NozzleInferenceEvaluator(model_path)
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    print(f"\nğŸ“¥ åŠ è½½æµ‹è¯•æ•°æ®: {data_path}")
    test_df = pd.read_csv(data_path)
    
    # é€‰æ‹©ç‰¹å®šæœºå™¨è¿›è¡Œæµ‹è¯•ï¼ˆä¾‹å¦‚æœºå™¨1ï¼‰
    test_machine_id = 1
    test_machine_df = test_df[test_df['machine_id'] == test_machine_id].copy()
    print(f"   é€‰æ‹©æœºå™¨ {test_machine_id} | æ ·æœ¬æ•°: {len(test_machine_df)}")
    
    # é€‰æ‹©æ—¶é—´èŒƒå›´ï¼ˆä¾‹å¦‚å‰10ç§’ï¼‰
    max_time = 10.0  # ç§’
    test_machine_df = test_machine_df[test_machine_df['timestamp'] <= max_time]
    print(f"   é€‰æ‹©æ—¶é—´èŒƒå›´ [0, {max_time}] ç§’ | æ ·æœ¬æ•°: {len(test_machine_df)}")
    
    # è¿›è¡Œé¢„æµ‹
    predictions = evaluator.predict(test_machine_df, batch_size=64)
    
    # è¯„ä¼°ç»“æœ
    evaluator.evaluate(predictions, test_machine_df)
    
    print("\n" + "="*70)
    print("ğŸ‰ æ¨ç†è¯„ä¼°å®Œæˆï¼")
    print("="*70)

if __name__ == "__main__":
    main()